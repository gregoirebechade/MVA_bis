{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b82071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154addb",
   "metadata": {},
   "source": [
    "# Opérations sur les tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799502f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenseur de dimensions torch.Size([10, 5, 100]) et de type torch.float32\n"
     ]
    }
   ],
   "source": [
    "#Création d'un tenseur\n",
    "tenseur = torch.zeros((10,5,100)) # [10,5,100]\n",
    "tenseur = torch.ones((10,5,100)) # [10,5,100]\n",
    "tenseur = torch.rand((10,5,100)) # [10,5,100]\n",
    "\n",
    "tenseur_zeros = torch.zeros_like(tenseur) # [10,5,100]\n",
    "tenseur_copy = torch.clone(tenseur)\n",
    "\n",
    "print(f'Tenseur de dimensions {tenseur.shape} et de type {tenseur.dtype}')\n",
    "\n",
    "# Opération élémentaires\n",
    "tenseur2 = torch.rand((10,5,100))  # [10,5,100]\n",
    "tenseur_au_carre = tenseur**2  # [10,5,100]\n",
    "tenseur_exp = torch.exp(tenseur)  # [10,5,100]\n",
    "tenseur_somme = tenseur + tenseur2  # [10,5,100]\n",
    "tenseur_produit = tenseur * tenseur2  # [10,5,100]\n",
    "\n",
    "# Concaténation\n",
    "tenseur_concatene_axe0 = torch.cat([tenseur, tenseur2],axis=0)  # [20,5,100]\n",
    "tenseur_concatene_axe1 = torch.cat([tenseur, tenseur2],axis=1)  # [10,10,100]\n",
    "tenseur_concatene_axe2 = torch.cat([tenseur, tenseur2],axis=2)  # [10,5,200]\n",
    "\n",
    "tenseur_tile = torch.tile(tenseur,dims=(2,3,4))  # [20,15,400]\n",
    "\n",
    "# Opérations de réduction\n",
    "tenseur_reduit_axe0 = torch.mean(tenseur,axis=0)  # [5,100]\n",
    "tenseur_reduit_axe1 = torch.mean(tenseur,axis=1)  # [10,100]\n",
    "tenseur_reduit_axe2 = torch.mean(tenseur,axis=2)  # [10,5]\n",
    "\n",
    "tenseur_reduit_axe0_kd = torch.mean(tenseur,axis=0,keepdim=True)  # [1,5,100]\n",
    "\n",
    "# Manipulation sur les dimensions \n",
    "\n",
    "tenseur_21 = torch.transpose(tenseur,1,2) # [10,100,5]\n",
    "tenseur_flat = torch.flatten(tenseur) # [5000,]\n",
    "tenseur_newdim_0 = torch.unsqueeze(tenseur,dim=0) # [1,10,5,100]\n",
    "tenseur_newdim_1 = torch.unsqueeze(tenseur,dim=1) # [10,1,5,100]\n",
    "\n",
    "# Slicing \n",
    "tenseur_partie = tenseur[0,:,:] # [5,100]\n",
    "tenseur_partie = tenseur[0,...] # [5,100]\n",
    "tenseur_partie = tenseur[0:5,:,:] # [5,5,100]\n",
    "tenseur_partie = tenseur[0,:,0::2]# [10,5,50]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531217b",
   "metadata": {},
   "source": [
    "# Optimisation d'un graphe de calculs\n",
    "Exemple : régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fec3fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 0:\n",
      "a: 0.0000, b: 0.0000, loss: 0.4857,  grad a: -0.3780, grad b: 0.2153\n",
      "Itération 1:\n",
      "a: 0.0378, b: -0.0215, loss: 0.4669,  grad a: -0.3732, grad b: 0.2060\n",
      "Itération 2:\n",
      "a: 0.0751, b: -0.0421, loss: 0.4490,  grad a: -0.3679, grad b: 0.1981\n",
      "Itération 3:\n",
      "a: 0.1119, b: -0.0619, loss: 0.4317,  grad a: -0.3622, grad b: 0.1913\n",
      "Itération 4:\n",
      "a: 0.1481, b: -0.0811, loss: 0.4151,  grad a: -0.3563, grad b: 0.1854\n",
      "Itération 5:\n",
      "a: 0.1838, b: -0.0996, loss: 0.3991,  grad a: -0.3502, grad b: 0.1801\n",
      "Itération 6:\n",
      "a: 0.2188, b: -0.1176, loss: 0.3837,  grad a: -0.3440, grad b: 0.1753\n",
      "Itération 7:\n",
      "a: 0.2532, b: -0.1352, loss: 0.3690,  grad a: -0.3378, grad b: 0.1710\n",
      "Itération 8:\n",
      "a: 0.2870, b: -0.1522, loss: 0.3548,  grad a: -0.3316, grad b: 0.1669\n",
      "Itération 9:\n",
      "a: 0.3201, b: -0.1689, loss: 0.3411,  grad a: -0.3254, grad b: 0.1631\n",
      "Itération 10:\n",
      "a: 0.3527, b: -0.1852, loss: 0.3280,  grad a: -0.3193, grad b: 0.1595\n",
      "Itération 11:\n",
      "a: 0.3846, b: -0.2012, loss: 0.3154,  grad a: -0.3133, grad b: 0.1561\n",
      "Itération 12:\n",
      "a: 0.4159, b: -0.2168, loss: 0.3033,  grad a: -0.3073, grad b: 0.1528\n",
      "Itération 13:\n",
      "a: 0.4467, b: -0.2321, loss: 0.2916,  grad a: -0.3014, grad b: 0.1497\n",
      "Itération 14:\n",
      "a: 0.4768, b: -0.2471, loss: 0.2804,  grad a: -0.2956, grad b: 0.1467\n",
      "Itération 15:\n",
      "a: 0.5064, b: -0.2617, loss: 0.2696,  grad a: -0.2899, grad b: 0.1437\n",
      "Itération 16:\n",
      "a: 0.5354, b: -0.2761, loss: 0.2592,  grad a: -0.2844, grad b: 0.1408\n",
      "Itération 17:\n",
      "a: 0.5638, b: -0.2902, loss: 0.2492,  grad a: -0.2789, grad b: 0.1380\n",
      "Itération 18:\n",
      "a: 0.5917, b: -0.3040, loss: 0.2397,  grad a: -0.2735, grad b: 0.1353\n",
      "Itération 19:\n",
      "a: 0.6190, b: -0.3175, loss: 0.2304,  grad a: -0.2682, grad b: 0.1327\n",
      "Itération 20:\n",
      "a: 0.6458, b: -0.3308, loss: 0.2216,  grad a: -0.2630, grad b: 0.1301\n",
      "Itération 21:\n",
      "a: 0.6721, b: -0.3438, loss: 0.2130,  grad a: -0.2579, grad b: 0.1275\n",
      "Itération 22:\n",
      "a: 0.6979, b: -0.3565, loss: 0.2049,  grad a: -0.2529, grad b: 0.1250\n",
      "Itération 23:\n",
      "a: 0.7232, b: -0.3690, loss: 0.1970,  grad a: -0.2480, grad b: 0.1226\n",
      "Itération 24:\n",
      "a: 0.7480, b: -0.3813, loss: 0.1894,  grad a: -0.2432, grad b: 0.1202\n",
      "Itération 25:\n",
      "a: 0.7723, b: -0.3933, loss: 0.1821,  grad a: -0.2384, grad b: 0.1179\n",
      "Itération 26:\n",
      "a: 0.7962, b: -0.4051, loss: 0.1751,  grad a: -0.2338, grad b: 0.1156\n",
      "Itération 27:\n",
      "a: 0.8195, b: -0.4167, loss: 0.1684,  grad a: -0.2293, grad b: 0.1133\n",
      "Itération 28:\n",
      "a: 0.8425, b: -0.4280, loss: 0.1619,  grad a: -0.2248, grad b: 0.1111\n",
      "Itération 29:\n",
      "a: 0.8650, b: -0.4391, loss: 0.1557,  grad a: -0.2205, grad b: 0.1089\n",
      "Itération 30:\n",
      "a: 0.8870, b: -0.4500, loss: 0.1497,  grad a: -0.2162, grad b: 0.1068\n",
      "Itération 31:\n",
      "a: 0.9086, b: -0.4607, loss: 0.1439,  grad a: -0.2120, grad b: 0.1048\n",
      "Itération 32:\n",
      "a: 0.9298, b: -0.4712, loss: 0.1384,  grad a: -0.2079, grad b: 0.1027\n",
      "Itération 33:\n",
      "a: 0.9506, b: -0.4814, loss: 0.1331,  grad a: -0.2038, grad b: 0.1007\n",
      "Itération 34:\n",
      "a: 0.9710, b: -0.4915, loss: 0.1279,  grad a: -0.1999, grad b: 0.0988\n",
      "Itération 35:\n",
      "a: 0.9910, b: -0.5014, loss: 0.1230,  grad a: -0.1960, grad b: 0.0968\n",
      "Itération 36:\n",
      "a: 1.0106, b: -0.5111, loss: 0.1183,  grad a: -0.1922, grad b: 0.0950\n",
      "Itération 37:\n",
      "a: 1.0298, b: -0.5206, loss: 0.1137,  grad a: -0.1884, grad b: 0.0931\n",
      "Itération 38:\n",
      "a: 1.0486, b: -0.5299, loss: 0.1094,  grad a: -0.1848, grad b: 0.0913\n",
      "Itération 39:\n",
      "a: 1.0671, b: -0.5390, loss: 0.1052,  grad a: -0.1812, grad b: 0.0895\n",
      "Itération 40:\n",
      "a: 1.0852, b: -0.5480, loss: 0.1011,  grad a: -0.1777, grad b: 0.0878\n",
      "Itération 41:\n",
      "a: 1.1030, b: -0.5567, loss: 0.0972,  grad a: -0.1742, grad b: 0.0861\n",
      "Itération 42:\n",
      "a: 1.1204, b: -0.5653, loss: 0.0935,  grad a: -0.1708, grad b: 0.0844\n",
      "Itération 43:\n",
      "a: 1.1375, b: -0.5738, loss: 0.0899,  grad a: -0.1675, grad b: 0.0828\n",
      "Itération 44:\n",
      "a: 1.1542, b: -0.5821, loss: 0.0864,  grad a: -0.1643, grad b: 0.0812\n",
      "Itération 45:\n",
      "a: 1.1707, b: -0.5902, loss: 0.0831,  grad a: -0.1611, grad b: 0.0796\n",
      "Itération 46:\n",
      "a: 1.1868, b: -0.5981, loss: 0.0799,  grad a: -0.1579, grad b: 0.0781\n",
      "Itération 47:\n",
      "a: 1.2026, b: -0.6059, loss: 0.0768,  grad a: -0.1549, grad b: 0.0765\n",
      "Itération 48:\n",
      "a: 1.2181, b: -0.6136, loss: 0.0739,  grad a: -0.1519, grad b: 0.0750\n",
      "Itération 49:\n",
      "a: 1.2333, b: -0.6211, loss: 0.0710,  grad a: -0.1489, grad b: 0.0736\n",
      "Itération 50:\n",
      "a: 1.2481, b: -0.6285, loss: 0.0683,  grad a: -0.1460, grad b: 0.0722\n",
      "Itération 51:\n",
      "a: 1.2627, b: -0.6357, loss: 0.0657,  grad a: -0.1432, grad b: 0.0708\n",
      "Itération 52:\n",
      "a: 1.2771, b: -0.6428, loss: 0.0631,  grad a: -0.1404, grad b: 0.0694\n",
      "Itération 53:\n",
      "a: 1.2911, b: -0.6497, loss: 0.0607,  grad a: -0.1377, grad b: 0.0680\n",
      "Itération 54:\n",
      "a: 1.3049, b: -0.6565, loss: 0.0584,  grad a: -0.1350, grad b: 0.0667\n",
      "Itération 55:\n",
      "a: 1.3184, b: -0.6632, loss: 0.0561,  grad a: -0.1324, grad b: 0.0654\n",
      "Itération 56:\n",
      "a: 1.3316, b: -0.6697, loss: 0.0540,  grad a: -0.1298, grad b: 0.0641\n",
      "Itération 57:\n",
      "a: 1.3446, b: -0.6761, loss: 0.0519,  grad a: -0.1273, grad b: 0.0629\n",
      "Itération 58:\n",
      "a: 1.3573, b: -0.6824, loss: 0.0499,  grad a: -0.1248, grad b: 0.0617\n",
      "Itération 59:\n",
      "a: 1.3698, b: -0.6886, loss: 0.0480,  grad a: -0.1224, grad b: 0.0605\n",
      "Itération 60:\n",
      "a: 1.3820, b: -0.6946, loss: 0.0461,  grad a: -0.1200, grad b: 0.0593\n",
      "Itération 61:\n",
      "a: 1.3941, b: -0.7006, loss: 0.0444,  grad a: -0.1177, grad b: 0.0582\n",
      "Itération 62:\n",
      "a: 1.4058, b: -0.7064, loss: 0.0427,  grad a: -0.1154, grad b: 0.0570\n",
      "Itération 63:\n",
      "a: 1.4174, b: -0.7121, loss: 0.0410,  grad a: -0.1132, grad b: 0.0559\n",
      "Itération 64:\n",
      "a: 1.4287, b: -0.7177, loss: 0.0394,  grad a: -0.1110, grad b: 0.0548\n",
      "Itération 65:\n",
      "a: 1.4398, b: -0.7232, loss: 0.0379,  grad a: -0.1088, grad b: 0.0538\n",
      "Itération 66:\n",
      "a: 1.4507, b: -0.7285, loss: 0.0365,  grad a: -0.1067, grad b: 0.0527\n",
      "Itération 67:\n",
      "a: 1.4613, b: -0.7338, loss: 0.0351,  grad a: -0.1046, grad b: 0.0517\n",
      "Itération 68:\n",
      "a: 1.4718, b: -0.7390, loss: 0.0337,  grad a: -0.1026, grad b: 0.0507\n",
      "Itération 69:\n",
      "a: 1.4820, b: -0.7441, loss: 0.0324,  grad a: -0.1006, grad b: 0.0497\n",
      "Itération 70:\n",
      "a: 1.4921, b: -0.7490, loss: 0.0312,  grad a: -0.0986, grad b: 0.0487\n",
      "Itération 71:\n",
      "a: 1.5020, b: -0.7539, loss: 0.0300,  grad a: -0.0967, grad b: 0.0478\n",
      "Itération 72:\n",
      "a: 1.5116, b: -0.7587, loss: 0.0288,  grad a: -0.0949, grad b: 0.0469\n",
      "Itération 73:\n",
      "a: 1.5211, b: -0.7634, loss: 0.0277,  grad a: -0.0930, grad b: 0.0460\n",
      "Itération 74:\n",
      "a: 1.5304, b: -0.7680, loss: 0.0266,  grad a: -0.0912, grad b: 0.0451\n",
      "Itération 75:\n",
      "a: 1.5395, b: -0.7725, loss: 0.0256,  grad a: -0.0894, grad b: 0.0442\n",
      "Itération 76:\n",
      "a: 1.5485, b: -0.7769, loss: 0.0246,  grad a: -0.0877, grad b: 0.0433\n",
      "Itération 77:\n",
      "a: 1.5573, b: -0.7812, loss: 0.0237,  grad a: -0.0860, grad b: 0.0425\n",
      "Itération 78:\n",
      "a: 1.5659, b: -0.7855, loss: 0.0228,  grad a: -0.0843, grad b: 0.0417\n",
      "Itération 79:\n",
      "a: 1.5743, b: -0.7896, loss: 0.0219,  grad a: -0.0827, grad b: 0.0409\n",
      "Itération 80:\n",
      "a: 1.5826, b: -0.7937, loss: 0.0211,  grad a: -0.0811, grad b: 0.0401\n",
      "Itération 81:\n",
      "a: 1.5907, b: -0.7977, loss: 0.0202,  grad a: -0.0795, grad b: 0.0393\n",
      "Itération 82:\n",
      "a: 1.5986, b: -0.8017, loss: 0.0195,  grad a: -0.0780, grad b: 0.0385\n",
      "Itération 83:\n",
      "a: 1.6064, b: -0.8055, loss: 0.0187,  grad a: -0.0764, grad b: 0.0378\n",
      "Itération 84:\n",
      "a: 1.6141, b: -0.8093, loss: 0.0180,  grad a: -0.0750, grad b: 0.0370\n",
      "Itération 85:\n",
      "a: 1.6216, b: -0.8130, loss: 0.0173,  grad a: -0.0735, grad b: 0.0363\n",
      "Itération 86:\n",
      "a: 1.6289, b: -0.8166, loss: 0.0166,  grad a: -0.0721, grad b: 0.0356\n",
      "Itération 87:\n",
      "a: 1.6361, b: -0.8202, loss: 0.0160,  grad a: -0.0707, grad b: 0.0349\n",
      "Itération 88:\n",
      "a: 1.6432, b: -0.8237, loss: 0.0154,  grad a: -0.0693, grad b: 0.0342\n",
      "Itération 89:\n",
      "a: 1.6501, b: -0.8271, loss: 0.0148,  grad a: -0.0680, grad b: 0.0336\n",
      "Itération 90:\n",
      "a: 1.6569, b: -0.8305, loss: 0.0142,  grad a: -0.0666, grad b: 0.0329\n",
      "Itération 91:\n",
      "a: 1.6636, b: -0.8338, loss: 0.0137,  grad a: -0.0653, grad b: 0.0323\n",
      "Itération 92:\n",
      "a: 1.6701, b: -0.8370, loss: 0.0131,  grad a: -0.0641, grad b: 0.0317\n",
      "Itération 93:\n",
      "a: 1.6765, b: -0.8401, loss: 0.0126,  grad a: -0.0628, grad b: 0.0310\n",
      "Itération 94:\n",
      "a: 1.6828, b: -0.8433, loss: 0.0122,  grad a: -0.0616, grad b: 0.0304\n",
      "Itération 95:\n",
      "a: 1.6890, b: -0.8463, loss: 0.0117,  grad a: -0.0604, grad b: 0.0299\n",
      "Itération 96:\n",
      "a: 1.6950, b: -0.8493, loss: 0.0112,  grad a: -0.0592, grad b: 0.0293\n",
      "Itération 97:\n",
      "a: 1.7009, b: -0.8522, loss: 0.0108,  grad a: -0.0581, grad b: 0.0287\n",
      "Itération 98:\n",
      "a: 1.7067, b: -0.8551, loss: 0.0104,  grad a: -0.0570, grad b: 0.0281\n",
      "Itération 99:\n",
      "a: 1.7124, b: -0.8579, loss: 0.0100,  grad a: -0.0559, grad b: 0.0276\n",
      "Itération 100:\n",
      "a: 1.7180, b: -0.8607, loss: 0.0096,  grad a: -0.0548, grad b: 0.0271\n",
      "Itération 101:\n",
      "a: 1.7235, b: -0.8634, loss: 0.0092,  grad a: -0.0537, grad b: 0.0265\n",
      "Itération 102:\n",
      "a: 1.7289, b: -0.8660, loss: 0.0089,  grad a: -0.0527, grad b: 0.0260\n",
      "Itération 103:\n",
      "a: 1.7341, b: -0.8686, loss: 0.0085,  grad a: -0.0516, grad b: 0.0255\n",
      "Itération 104:\n",
      "a: 1.7393, b: -0.8712, loss: 0.0082,  grad a: -0.0506, grad b: 0.0250\n",
      "Itération 105:\n",
      "a: 1.7444, b: -0.8737, loss: 0.0079,  grad a: -0.0497, grad b: 0.0245\n",
      "Itération 106:\n",
      "a: 1.7493, b: -0.8761, loss: 0.0076,  grad a: -0.0487, grad b: 0.0241\n",
      "Itération 107:\n",
      "a: 1.7542, b: -0.8785, loss: 0.0073,  grad a: -0.0477, grad b: 0.0236\n",
      "Itération 108:\n",
      "a: 1.7590, b: -0.8809, loss: 0.0070,  grad a: -0.0468, grad b: 0.0231\n",
      "Itération 109:\n",
      "a: 1.7636, b: -0.8832, loss: 0.0067,  grad a: -0.0459, grad b: 0.0227\n",
      "Itération 110:\n",
      "a: 1.7682, b: -0.8855, loss: 0.0065,  grad a: -0.0450, grad b: 0.0222\n",
      "Itération 111:\n",
      "a: 1.7727, b: -0.8877, loss: 0.0062,  grad a: -0.0441, grad b: 0.0218\n",
      "Itération 112:\n",
      "a: 1.7771, b: -0.8899, loss: 0.0060,  grad a: -0.0433, grad b: 0.0214\n",
      "Itération 113:\n",
      "a: 1.7815, b: -0.8920, loss: 0.0058,  grad a: -0.0424, grad b: 0.0210\n",
      "Itération 114:\n",
      "a: 1.7857, b: -0.8941, loss: 0.0055,  grad a: -0.0416, grad b: 0.0206\n",
      "Itération 115:\n",
      "a: 1.7899, b: -0.8962, loss: 0.0053,  grad a: -0.0408, grad b: 0.0202\n",
      "Itération 116:\n",
      "a: 1.7940, b: -0.8982, loss: 0.0051,  grad a: -0.0400, grad b: 0.0198\n",
      "Itération 117:\n",
      "a: 1.7980, b: -0.9002, loss: 0.0049,  grad a: -0.0392, grad b: 0.0194\n",
      "Itération 118:\n",
      "a: 1.8019, b: -0.9021, loss: 0.0047,  grad a: -0.0385, grad b: 0.0190\n",
      "Itération 119:\n",
      "a: 1.8057, b: -0.9040, loss: 0.0046,  grad a: -0.0377, grad b: 0.0186\n",
      "Itération 120:\n",
      "a: 1.8095, b: -0.9059, loss: 0.0044,  grad a: -0.0370, grad b: 0.0183\n",
      "Itération 121:\n",
      "a: 1.8132, b: -0.9077, loss: 0.0042,  grad a: -0.0363, grad b: 0.0179\n",
      "Itération 122:\n",
      "a: 1.8168, b: -0.9095, loss: 0.0041,  grad a: -0.0356, grad b: 0.0176\n",
      "Itération 123:\n",
      "a: 1.8204, b: -0.9112, loss: 0.0039,  grad a: -0.0349, grad b: 0.0172\n",
      "Itération 124:\n",
      "a: 1.8239, b: -0.9130, loss: 0.0037,  grad a: -0.0342, grad b: 0.0169\n",
      "Itération 125:\n",
      "a: 1.8273, b: -0.9147, loss: 0.0036,  grad a: -0.0335, grad b: 0.0166\n",
      "Itération 126:\n",
      "a: 1.8307, b: -0.9163, loss: 0.0035,  grad a: -0.0329, grad b: 0.0163\n",
      "Itération 127:\n",
      "a: 1.8339, b: -0.9179, loss: 0.0033,  grad a: -0.0323, grad b: 0.0159\n",
      "Itération 128:\n",
      "a: 1.8372, b: -0.9195, loss: 0.0032,  grad a: -0.0316, grad b: 0.0156\n",
      "Itération 129:\n",
      "a: 1.8403, b: -0.9211, loss: 0.0031,  grad a: -0.0310, grad b: 0.0153\n",
      "Itération 130:\n",
      "a: 1.8434, b: -0.9226, loss: 0.0030,  grad a: -0.0304, grad b: 0.0150\n",
      "Itération 131:\n",
      "a: 1.8465, b: -0.9241, loss: 0.0028,  grad a: -0.0298, grad b: 0.0147\n",
      "Itération 132:\n",
      "a: 1.8495, b: -0.9256, loss: 0.0027,  grad a: -0.0292, grad b: 0.0144\n",
      "Itération 133:\n",
      "a: 1.8524, b: -0.9271, loss: 0.0026,  grad a: -0.0287, grad b: 0.0142\n",
      "Itération 134:\n",
      "a: 1.8552, b: -0.9285, loss: 0.0025,  grad a: -0.0281, grad b: 0.0139\n",
      "Itération 135:\n",
      "a: 1.8581, b: -0.9299, loss: 0.0024,  grad a: -0.0276, grad b: 0.0136\n",
      "Itération 136:\n",
      "a: 1.8608, b: -0.9312, loss: 0.0023,  grad a: -0.0270, grad b: 0.0134\n",
      "Itération 137:\n",
      "a: 1.8635, b: -0.9326, loss: 0.0023,  grad a: -0.0265, grad b: 0.0131\n",
      "Itération 138:\n",
      "a: 1.8662, b: -0.9339, loss: 0.0022,  grad a: -0.0260, grad b: 0.0128\n",
      "Itération 139:\n",
      "a: 1.8688, b: -0.9352, loss: 0.0021,  grad a: -0.0255, grad b: 0.0126\n",
      "Itération 140:\n",
      "a: 1.8713, b: -0.9364, loss: 0.0020,  grad a: -0.0250, grad b: 0.0124\n",
      "Itération 141:\n",
      "a: 1.8738, b: -0.9376, loss: 0.0019,  grad a: -0.0245, grad b: 0.0121\n",
      "Itération 142:\n",
      "a: 1.8763, b: -0.9389, loss: 0.0018,  grad a: -0.0240, grad b: 0.0119\n",
      "Itération 143:\n",
      "a: 1.8787, b: -0.9400, loss: 0.0018,  grad a: -0.0236, grad b: 0.0116\n",
      "Itération 144:\n",
      "a: 1.8810, b: -0.9412, loss: 0.0017,  grad a: -0.0231, grad b: 0.0114\n",
      "Itération 145:\n",
      "a: 1.8833, b: -0.9424, loss: 0.0016,  grad a: -0.0227, grad b: 0.0112\n",
      "Itération 146:\n",
      "a: 1.8856, b: -0.9435, loss: 0.0016,  grad a: -0.0222, grad b: 0.0110\n",
      "Itération 147:\n",
      "a: 1.8878, b: -0.9446, loss: 0.0015,  grad a: -0.0218, grad b: 0.0108\n",
      "Itération 148:\n",
      "a: 1.8900, b: -0.9456, loss: 0.0015,  grad a: -0.0214, grad b: 0.0106\n",
      "Itération 149:\n",
      "a: 1.8921, b: -0.9467, loss: 0.0014,  grad a: -0.0209, grad b: 0.0104\n",
      "Itération 150:\n",
      "a: 1.8942, b: -0.9477, loss: 0.0014,  grad a: -0.0205, grad b: 0.0102\n",
      "Itération 151:\n",
      "a: 1.8963, b: -0.9488, loss: 0.0013,  grad a: -0.0201, grad b: 0.0100\n",
      "Itération 152:\n",
      "a: 1.8983, b: -0.9497, loss: 0.0012,  grad a: -0.0198, grad b: 0.0098\n",
      "Itération 153:\n",
      "a: 1.9003, b: -0.9507, loss: 0.0012,  grad a: -0.0194, grad b: 0.0096\n",
      "Itération 154:\n",
      "a: 1.9022, b: -0.9517, loss: 0.0012,  grad a: -0.0190, grad b: 0.0094\n",
      "Itération 155:\n",
      "a: 1.9041, b: -0.9526, loss: 0.0011,  grad a: -0.0186, grad b: 0.0092\n",
      "Itération 156:\n",
      "a: 1.9060, b: -0.9535, loss: 0.0011,  grad a: -0.0183, grad b: 0.0090\n",
      "Itération 157:\n",
      "a: 1.9078, b: -0.9544, loss: 0.0010,  grad a: -0.0179, grad b: 0.0088\n",
      "Itération 158:\n",
      "a: 1.9096, b: -0.9553, loss: 0.0010,  grad a: -0.0176, grad b: 0.0087\n",
      "Itération 159:\n",
      "a: 1.9114, b: -0.9562, loss: 0.0009,  grad a: -0.0172, grad b: 0.0085\n",
      "Itération 160:\n",
      "a: 1.9131, b: -0.9570, loss: 0.0009,  grad a: -0.0169, grad b: 0.0083\n",
      "Itération 161:\n",
      "a: 1.9148, b: -0.9579, loss: 0.0009,  grad a: -0.0166, grad b: 0.0082\n",
      "Itération 162:\n",
      "a: 1.9164, b: -0.9587, loss: 0.0008,  grad a: -0.0162, grad b: 0.0080\n",
      "Itération 163:\n",
      "a: 1.9180, b: -0.9595, loss: 0.0008,  grad a: -0.0159, grad b: 0.0079\n",
      "Itération 164:\n",
      "a: 1.9196, b: -0.9603, loss: 0.0008,  grad a: -0.0156, grad b: 0.0077\n",
      "Itération 165:\n",
      "a: 1.9212, b: -0.9611, loss: 0.0008,  grad a: -0.0153, grad b: 0.0076\n",
      "Itération 166:\n",
      "a: 1.9227, b: -0.9618, loss: 0.0007,  grad a: -0.0150, grad b: 0.0074\n",
      "Itération 167:\n",
      "a: 1.9242, b: -0.9626, loss: 0.0007,  grad a: -0.0147, grad b: 0.0073\n",
      "Itération 168:\n",
      "a: 1.9257, b: -0.9633, loss: 0.0007,  grad a: -0.0144, grad b: 0.0071\n",
      "Itération 169:\n",
      "a: 1.9271, b: -0.9640, loss: 0.0006,  grad a: -0.0142, grad b: 0.0070\n",
      "Itération 170:\n",
      "a: 1.9286, b: -0.9647, loss: 0.0006,  grad a: -0.0139, grad b: 0.0069\n",
      "Itération 171:\n",
      "a: 1.9299, b: -0.9654, loss: 0.0006,  grad a: -0.0136, grad b: 0.0067\n",
      "Itération 172:\n",
      "a: 1.9313, b: -0.9661, loss: 0.0006,  grad a: -0.0133, grad b: 0.0066\n",
      "Itération 173:\n",
      "a: 1.9326, b: -0.9667, loss: 0.0005,  grad a: -0.0131, grad b: 0.0065\n",
      "Itération 174:\n",
      "a: 1.9339, b: -0.9674, loss: 0.0005,  grad a: -0.0128, grad b: 0.0063\n",
      "Itération 175:\n",
      "a: 1.9352, b: -0.9680, loss: 0.0005,  grad a: -0.0126, grad b: 0.0062\n",
      "Itération 176:\n",
      "a: 1.9365, b: -0.9686, loss: 0.0005,  grad a: -0.0123, grad b: 0.0061\n",
      "Itération 177:\n",
      "a: 1.9377, b: -0.9692, loss: 0.0005,  grad a: -0.0121, grad b: 0.0060\n",
      "Itération 178:\n",
      "a: 1.9389, b: -0.9698, loss: 0.0005,  grad a: -0.0119, grad b: 0.0059\n",
      "Itération 179:\n",
      "a: 1.9401, b: -0.9704, loss: 0.0004,  grad a: -0.0116, grad b: 0.0057\n",
      "Itération 180:\n",
      "a: 1.9413, b: -0.9710, loss: 0.0004,  grad a: -0.0114, grad b: 0.0056\n",
      "Itération 181:\n",
      "a: 1.9424, b: -0.9715, loss: 0.0004,  grad a: -0.0112, grad b: 0.0055\n",
      "Itération 182:\n",
      "a: 1.9435, b: -0.9721, loss: 0.0004,  grad a: -0.0110, grad b: 0.0054\n",
      "Itération 183:\n",
      "a: 1.9446, b: -0.9726, loss: 0.0004,  grad a: -0.0108, grad b: 0.0053\n",
      "Itération 184:\n",
      "a: 1.9457, b: -0.9732, loss: 0.0004,  grad a: -0.0105, grad b: 0.0052\n",
      "Itération 185:\n",
      "a: 1.9468, b: -0.9737, loss: 0.0003,  grad a: -0.0103, grad b: 0.0051\n",
      "Itération 186:\n",
      "a: 1.9478, b: -0.9742, loss: 0.0003,  grad a: -0.0101, grad b: 0.0050\n",
      "Itération 187:\n",
      "a: 1.9488, b: -0.9747, loss: 0.0003,  grad a: -0.0099, grad b: 0.0049\n",
      "Itération 188:\n",
      "a: 1.9498, b: -0.9752, loss: 0.0003,  grad a: -0.0097, grad b: 0.0048\n",
      "Itération 189:\n",
      "a: 1.9508, b: -0.9757, loss: 0.0003,  grad a: -0.0096, grad b: 0.0047\n",
      "Itération 190:\n",
      "a: 1.9517, b: -0.9762, loss: 0.0003,  grad a: -0.0094, grad b: 0.0046\n",
      "Itération 191:\n",
      "a: 1.9527, b: -0.9766, loss: 0.0003,  grad a: -0.0092, grad b: 0.0045\n",
      "Itération 192:\n",
      "a: 1.9536, b: -0.9771, loss: 0.0003,  grad a: -0.0090, grad b: 0.0045\n",
      "Itération 193:\n",
      "a: 1.9545, b: -0.9775, loss: 0.0003,  grad a: -0.0088, grad b: 0.0044\n",
      "Itération 194:\n",
      "a: 1.9554, b: -0.9780, loss: 0.0002,  grad a: -0.0087, grad b: 0.0043\n",
      "Itération 195:\n",
      "a: 1.9562, b: -0.9784, loss: 0.0002,  grad a: -0.0085, grad b: 0.0042\n",
      "Itération 196:\n",
      "a: 1.9571, b: -0.9788, loss: 0.0002,  grad a: -0.0083, grad b: 0.0041\n",
      "Itération 197:\n",
      "a: 1.9579, b: -0.9792, loss: 0.0002,  grad a: -0.0082, grad b: 0.0040\n",
      "Itération 198:\n",
      "a: 1.9587, b: -0.9796, loss: 0.0002,  grad a: -0.0080, grad b: 0.0040\n",
      "Itération 199:\n",
      "a: 1.9595, b: -0.9800, loss: 0.0002,  grad a: -0.0079, grad b: 0.0039\n",
      "Itération 200:\n",
      "a: 1.9603, b: -0.9804, loss: 0.0002,  grad a: -0.0077, grad b: 0.0038\n",
      "Itération 201:\n",
      "a: 1.9611, b: -0.9808, loss: 0.0002,  grad a: -0.0076, grad b: 0.0037\n",
      "Itération 202:\n",
      "a: 1.9619, b: -0.9812, loss: 0.0002,  grad a: -0.0074, grad b: 0.0037\n",
      "Itération 203:\n",
      "a: 1.9626, b: -0.9815, loss: 0.0002,  grad a: -0.0073, grad b: 0.0036\n",
      "Itération 204:\n",
      "a: 1.9633, b: -0.9819, loss: 0.0002,  grad a: -0.0071, grad b: 0.0035\n",
      "Itération 205:\n",
      "a: 1.9640, b: -0.9822, loss: 0.0002,  grad a: -0.0070, grad b: 0.0035\n",
      "Itération 206:\n",
      "a: 1.9647, b: -0.9826, loss: 0.0002,  grad a: -0.0068, grad b: 0.0034\n",
      "Itération 207:\n",
      "a: 1.9654, b: -0.9829, loss: 0.0001,  grad a: -0.0067, grad b: 0.0033\n",
      "Itération 208:\n",
      "a: 1.9661, b: -0.9832, loss: 0.0001,  grad a: -0.0066, grad b: 0.0033\n",
      "Itération 209:\n",
      "a: 1.9668, b: -0.9836, loss: 0.0001,  grad a: -0.0065, grad b: 0.0032\n",
      "Itération 210:\n",
      "a: 1.9674, b: -0.9839, loss: 0.0001,  grad a: -0.0063, grad b: 0.0031\n",
      "Itération 211:\n",
      "a: 1.9680, b: -0.9842, loss: 0.0001,  grad a: -0.0062, grad b: 0.0031\n",
      "Itération 212:\n",
      "a: 1.9687, b: -0.9845, loss: 0.0001,  grad a: -0.0061, grad b: 0.0030\n",
      "Itération 213:\n",
      "a: 1.9693, b: -0.9848, loss: 0.0001,  grad a: -0.0060, grad b: 0.0030\n",
      "Itération 214:\n",
      "a: 1.9699, b: -0.9851, loss: 0.0001,  grad a: -0.0059, grad b: 0.0029\n",
      "Itération 215:\n",
      "a: 1.9704, b: -0.9854, loss: 0.0001,  grad a: -0.0057, grad b: 0.0028\n",
      "Itération 216:\n",
      "a: 1.9710, b: -0.9857, loss: 0.0001,  grad a: -0.0056, grad b: 0.0028\n",
      "Itération 217:\n",
      "a: 1.9716, b: -0.9860, loss: 0.0001,  grad a: -0.0055, grad b: 0.0027\n",
      "Itération 218:\n",
      "a: 1.9721, b: -0.9862, loss: 0.0001,  grad a: -0.0054, grad b: 0.0027\n",
      "Itération 219:\n",
      "a: 1.9727, b: -0.9865, loss: 0.0001,  grad a: -0.0053, grad b: 0.0026\n",
      "Itération 220:\n",
      "a: 1.9732, b: -0.9868, loss: 0.0001,  grad a: -0.0052, grad b: 0.0026\n",
      "Itération 221:\n",
      "a: 1.9737, b: -0.9870, loss: 0.0001,  grad a: -0.0051, grad b: 0.0025\n",
      "Itération 222:\n",
      "a: 1.9742, b: -0.9873, loss: 0.0001,  grad a: -0.0050, grad b: 0.0025\n",
      "Itération 223:\n",
      "a: 1.9747, b: -0.9875, loss: 0.0001,  grad a: -0.0049, grad b: 0.0024\n",
      "Itération 224:\n",
      "a: 1.9752, b: -0.9878, loss: 0.0001,  grad a: -0.0048, grad b: 0.0024\n",
      "Itération 225:\n",
      "a: 1.9757, b: -0.9880, loss: 0.0001,  grad a: -0.0047, grad b: 0.0023\n",
      "Itération 226:\n",
      "a: 1.9762, b: -0.9882, loss: 0.0001,  grad a: -0.0046, grad b: 0.0023\n",
      "Itération 227:\n",
      "a: 1.9766, b: -0.9885, loss: 0.0001,  grad a: -0.0045, grad b: 0.0022\n",
      "Itération 228:\n",
      "a: 1.9771, b: -0.9887, loss: 0.0001,  grad a: -0.0044, grad b: 0.0022\n",
      "Itération 229:\n",
      "a: 1.9775, b: -0.9889, loss: 0.0001,  grad a: -0.0044, grad b: 0.0022\n",
      "Itération 230:\n",
      "a: 1.9780, b: -0.9891, loss: 0.0001,  grad a: -0.0043, grad b: 0.0021\n",
      "Itération 231:\n",
      "a: 1.9784, b: -0.9893, loss: 0.0001,  grad a: -0.0042, grad b: 0.0021\n",
      "Itération 232:\n",
      "a: 1.9788, b: -0.9895, loss: 0.0001,  grad a: -0.0041, grad b: 0.0020\n",
      "Itération 233:\n",
      "a: 1.9792, b: -0.9897, loss: 0.0001,  grad a: -0.0040, grad b: 0.0020\n",
      "Itération 234:\n",
      "a: 1.9796, b: -0.9899, loss: 0.0001,  grad a: -0.0040, grad b: 0.0020\n",
      "Itération 235:\n",
      "a: 1.9800, b: -0.9901, loss: 0.0000,  grad a: -0.0039, grad b: 0.0019\n",
      "Itération 236:\n",
      "a: 1.9804, b: -0.9903, loss: 0.0000,  grad a: -0.0038, grad b: 0.0019\n",
      "Itération 237:\n",
      "a: 1.9808, b: -0.9905, loss: 0.0000,  grad a: -0.0037, grad b: 0.0018\n",
      "Itération 238:\n",
      "a: 1.9812, b: -0.9907, loss: 0.0000,  grad a: -0.0037, grad b: 0.0018\n",
      "Itération 239:\n",
      "a: 1.9815, b: -0.9909, loss: 0.0000,  grad a: -0.0036, grad b: 0.0018\n",
      "Itération 240:\n",
      "a: 1.9819, b: -0.9911, loss: 0.0000,  grad a: -0.0035, grad b: 0.0017\n",
      "Itération 241:\n",
      "a: 1.9823, b: -0.9912, loss: 0.0000,  grad a: -0.0034, grad b: 0.0017\n",
      "Itération 242:\n",
      "a: 1.9826, b: -0.9914, loss: 0.0000,  grad a: -0.0034, grad b: 0.0017\n",
      "Itération 243:\n",
      "a: 1.9829, b: -0.9916, loss: 0.0000,  grad a: -0.0033, grad b: 0.0016\n",
      "Itération 244:\n",
      "a: 1.9833, b: -0.9917, loss: 0.0000,  grad a: -0.0033, grad b: 0.0016\n",
      "Itération 245:\n",
      "a: 1.9836, b: -0.9919, loss: 0.0000,  grad a: -0.0032, grad b: 0.0016\n",
      "Itération 246:\n",
      "a: 1.9839, b: -0.9920, loss: 0.0000,  grad a: -0.0031, grad b: 0.0015\n",
      "Itération 247:\n",
      "a: 1.9842, b: -0.9922, loss: 0.0000,  grad a: -0.0031, grad b: 0.0015\n",
      "Itération 248:\n",
      "a: 1.9845, b: -0.9924, loss: 0.0000,  grad a: -0.0030, grad b: 0.0015\n",
      "Itération 249:\n",
      "a: 1.9848, b: -0.9925, loss: 0.0000,  grad a: -0.0029, grad b: 0.0015\n",
      "Itération 250:\n",
      "a: 1.9851, b: -0.9926, loss: 0.0000,  grad a: -0.0029, grad b: 0.0014\n",
      "Itération 251:\n",
      "a: 1.9854, b: -0.9928, loss: 0.0000,  grad a: -0.0028, grad b: 0.0014\n",
      "Itération 252:\n",
      "a: 1.9857, b: -0.9929, loss: 0.0000,  grad a: -0.0028, grad b: 0.0014\n",
      "Itération 253:\n",
      "a: 1.9860, b: -0.9931, loss: 0.0000,  grad a: -0.0027, grad b: 0.0013\n",
      "Itération 254:\n",
      "a: 1.9862, b: -0.9932, loss: 0.0000,  grad a: -0.0027, grad b: 0.0013\n",
      "Itération 255:\n",
      "a: 1.9865, b: -0.9933, loss: 0.0000,  grad a: -0.0026, grad b: 0.0013\n",
      "Itération 256:\n",
      "a: 1.9868, b: -0.9935, loss: 0.0000,  grad a: -0.0026, grad b: 0.0013\n",
      "Itération 257:\n",
      "a: 1.9870, b: -0.9936, loss: 0.0000,  grad a: -0.0025, grad b: 0.0012\n",
      "Itération 258:\n",
      "a: 1.9873, b: -0.9937, loss: 0.0000,  grad a: -0.0025, grad b: 0.0012\n",
      "Itération 259:\n",
      "a: 1.9875, b: -0.9938, loss: 0.0000,  grad a: -0.0024, grad b: 0.0012\n",
      "Itération 260:\n",
      "a: 1.9878, b: -0.9940, loss: 0.0000,  grad a: -0.0024, grad b: 0.0012\n",
      "Itération 261:\n",
      "a: 1.9880, b: -0.9941, loss: 0.0000,  grad a: -0.0023, grad b: 0.0012\n",
      "Itération 262:\n",
      "a: 1.9882, b: -0.9942, loss: 0.0000,  grad a: -0.0023, grad b: 0.0011\n",
      "Itération 263:\n",
      "a: 1.9885, b: -0.9943, loss: 0.0000,  grad a: -0.0022, grad b: 0.0011\n",
      "Itération 264:\n",
      "a: 1.9887, b: -0.9944, loss: 0.0000,  grad a: -0.0022, grad b: 0.0011\n",
      "Itération 265:\n",
      "a: 1.9889, b: -0.9945, loss: 0.0000,  grad a: -0.0022, grad b: 0.0011\n",
      "Itération 266:\n",
      "a: 1.9891, b: -0.9946, loss: 0.0000,  grad a: -0.0021, grad b: 0.0010\n",
      "Itération 267:\n",
      "a: 1.9893, b: -0.9947, loss: 0.0000,  grad a: -0.0021, grad b: 0.0010\n",
      "Itération 268:\n",
      "a: 1.9895, b: -0.9948, loss: 0.0000,  grad a: -0.0020, grad b: 0.0010\n",
      "Itération 269:\n",
      "a: 1.9898, b: -0.9949, loss: 0.0000,  grad a: -0.0020, grad b: 0.0010\n",
      "Itération 270:\n",
      "a: 1.9900, b: -0.9950, loss: 0.0000,  grad a: -0.0020, grad b: 0.0010\n",
      "Itération 271:\n",
      "a: 1.9901, b: -0.9951, loss: 0.0000,  grad a: -0.0019, grad b: 0.0009\n",
      "Itération 272:\n",
      "a: 1.9903, b: -0.9952, loss: 0.0000,  grad a: -0.0019, grad b: 0.0009\n",
      "Itération 273:\n",
      "a: 1.9905, b: -0.9953, loss: 0.0000,  grad a: -0.0018, grad b: 0.0009\n",
      "Itération 274:\n",
      "a: 1.9907, b: -0.9954, loss: 0.0000,  grad a: -0.0018, grad b: 0.0009\n",
      "Itération 275:\n",
      "a: 1.9909, b: -0.9955, loss: 0.0000,  grad a: -0.0018, grad b: 0.0009\n",
      "Itération 276:\n",
      "a: 1.9911, b: -0.9956, loss: 0.0000,  grad a: -0.0017, grad b: 0.0009\n",
      "Itération 277:\n",
      "a: 1.9912, b: -0.9957, loss: 0.0000,  grad a: -0.0017, grad b: 0.0008\n",
      "Itération 278:\n",
      "a: 1.9914, b: -0.9958, loss: 0.0000,  grad a: -0.0017, grad b: 0.0008\n",
      "Itération 279:\n",
      "a: 1.9916, b: -0.9958, loss: 0.0000,  grad a: -0.0016, grad b: 0.0008\n",
      "Itération 280:\n",
      "a: 1.9917, b: -0.9959, loss: 0.0000,  grad a: -0.0016, grad b: 0.0008\n",
      "Itération 281:\n",
      "a: 1.9919, b: -0.9960, loss: 0.0000,  grad a: -0.0016, grad b: 0.0008\n",
      "Itération 282:\n",
      "a: 1.9921, b: -0.9961, loss: 0.0000,  grad a: -0.0015, grad b: 0.0008\n",
      "Itération 283:\n",
      "a: 1.9922, b: -0.9962, loss: 0.0000,  grad a: -0.0015, grad b: 0.0007\n",
      "Itération 284:\n",
      "a: 1.9924, b: -0.9962, loss: 0.0000,  grad a: -0.0015, grad b: 0.0007\n",
      "Itération 285:\n",
      "a: 1.9925, b: -0.9963, loss: 0.0000,  grad a: -0.0015, grad b: 0.0007\n",
      "Itération 286:\n",
      "a: 1.9927, b: -0.9964, loss: 0.0000,  grad a: -0.0014, grad b: 0.0007\n",
      "Itération 287:\n",
      "a: 1.9928, b: -0.9964, loss: 0.0000,  grad a: -0.0014, grad b: 0.0007\n",
      "Itération 288:\n",
      "a: 1.9929, b: -0.9965, loss: 0.0000,  grad a: -0.0014, grad b: 0.0007\n",
      "Itération 289:\n",
      "a: 1.9931, b: -0.9966, loss: 0.0000,  grad a: -0.0013, grad b: 0.0007\n",
      "Itération 290:\n",
      "a: 1.9932, b: -0.9966, loss: 0.0000,  grad a: -0.0013, grad b: 0.0007\n",
      "Itération 291:\n",
      "a: 1.9933, b: -0.9967, loss: 0.0000,  grad a: -0.0013, grad b: 0.0006\n",
      "Itération 292:\n",
      "a: 1.9935, b: -0.9968, loss: 0.0000,  grad a: -0.0013, grad b: 0.0006\n",
      "Itération 293:\n",
      "a: 1.9936, b: -0.9968, loss: 0.0000,  grad a: -0.0012, grad b: 0.0006\n",
      "Itération 294:\n",
      "a: 1.9937, b: -0.9969, loss: 0.0000,  grad a: -0.0012, grad b: 0.0006\n",
      "Itération 295:\n",
      "a: 1.9938, b: -0.9970, loss: 0.0000,  grad a: -0.0012, grad b: 0.0006\n",
      "Itération 296:\n",
      "a: 1.9940, b: -0.9970, loss: 0.0000,  grad a: -0.0012, grad b: 0.0006\n",
      "Itération 297:\n",
      "a: 1.9941, b: -0.9971, loss: 0.0000,  grad a: -0.0011, grad b: 0.0006\n",
      "Itération 298:\n",
      "a: 1.9942, b: -0.9971, loss: 0.0000,  grad a: -0.0011, grad b: 0.0006\n",
      "Itération 299:\n",
      "a: 1.9943, b: -0.9972, loss: 0.0000,  grad a: -0.0011, grad b: 0.0005\n",
      "Itération 300:\n",
      "a: 1.9944, b: -0.9972, loss: 0.0000,  grad a: -0.0011, grad b: 0.0005\n",
      "Itération 301:\n",
      "a: 1.9945, b: -0.9973, loss: 0.0000,  grad a: -0.0011, grad b: 0.0005\n",
      "Itération 302:\n",
      "a: 1.9946, b: -0.9973, loss: 0.0000,  grad a: -0.0010, grad b: 0.0005\n",
      "Itération 303:\n",
      "a: 1.9947, b: -0.9974, loss: 0.0000,  grad a: -0.0010, grad b: 0.0005\n",
      "Itération 304:\n",
      "a: 1.9948, b: -0.9975, loss: 0.0000,  grad a: -0.0010, grad b: 0.0005\n",
      "Itération 305:\n",
      "a: 1.9949, b: -0.9975, loss: 0.0000,  grad a: -0.0010, grad b: 0.0005\n",
      "Itération 306:\n",
      "a: 1.9950, b: -0.9975, loss: 0.0000,  grad a: -0.0010, grad b: 0.0005\n",
      "Itération 307:\n",
      "a: 1.9951, b: -0.9976, loss: 0.0000,  grad a: -0.0009, grad b: 0.0005\n",
      "Itération 308:\n",
      "a: 1.9952, b: -0.9976, loss: 0.0000,  grad a: -0.0009, grad b: 0.0005\n",
      "Itération 309:\n",
      "a: 1.9953, b: -0.9977, loss: 0.0000,  grad a: -0.0009, grad b: 0.0004\n",
      "Itération 310:\n",
      "a: 1.9954, b: -0.9977, loss: 0.0000,  grad a: -0.0009, grad b: 0.0004\n",
      "Itération 311:\n",
      "a: 1.9955, b: -0.9978, loss: 0.0000,  grad a: -0.0009, grad b: 0.0004\n",
      "Itération 312:\n",
      "a: 1.9956, b: -0.9978, loss: 0.0000,  grad a: -0.0009, grad b: 0.0004\n",
      "Itération 313:\n",
      "a: 1.9957, b: -0.9979, loss: 0.0000,  grad a: -0.0008, grad b: 0.0004\n",
      "Itération 314:\n",
      "a: 1.9958, b: -0.9979, loss: 0.0000,  grad a: -0.0008, grad b: 0.0004\n",
      "Itération 315:\n",
      "a: 1.9958, b: -0.9979, loss: 0.0000,  grad a: -0.0008, grad b: 0.0004\n",
      "Itération 316:\n",
      "a: 1.9959, b: -0.9980, loss: 0.0000,  grad a: -0.0008, grad b: 0.0004\n",
      "Itération 317:\n",
      "a: 1.9960, b: -0.9980, loss: 0.0000,  grad a: -0.0008, grad b: 0.0004\n",
      "Itération 318:\n",
      "a: 1.9961, b: -0.9981, loss: 0.0000,  grad a: -0.0008, grad b: 0.0004\n",
      "Itération 319:\n",
      "a: 1.9962, b: -0.9981, loss: 0.0000,  grad a: -0.0007, grad b: 0.0004\n",
      "Itération 320:\n",
      "a: 1.9962, b: -0.9981, loss: 0.0000,  grad a: -0.0007, grad b: 0.0004\n",
      "Itération 321:\n",
      "a: 1.9963, b: -0.9982, loss: 0.0000,  grad a: -0.0007, grad b: 0.0004\n",
      "Itération 322:\n",
      "a: 1.9964, b: -0.9982, loss: 0.0000,  grad a: -0.0007, grad b: 0.0003\n",
      "Itération 323:\n",
      "a: 1.9964, b: -0.9982, loss: 0.0000,  grad a: -0.0007, grad b: 0.0003\n",
      "Itération 324:\n",
      "a: 1.9965, b: -0.9983, loss: 0.0000,  grad a: -0.0007, grad b: 0.0003\n",
      "Itération 325:\n",
      "a: 1.9966, b: -0.9983, loss: 0.0000,  grad a: -0.0007, grad b: 0.0003\n",
      "Itération 326:\n",
      "a: 1.9966, b: -0.9983, loss: 0.0000,  grad a: -0.0007, grad b: 0.0003\n",
      "Itération 327:\n",
      "a: 1.9967, b: -0.9984, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 328:\n",
      "a: 1.9968, b: -0.9984, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 329:\n",
      "a: 1.9968, b: -0.9984, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 330:\n",
      "a: 1.9969, b: -0.9985, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 331:\n",
      "a: 1.9970, b: -0.9985, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 332:\n",
      "a: 1.9970, b: -0.9985, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 333:\n",
      "a: 1.9971, b: -0.9986, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 334:\n",
      "a: 1.9971, b: -0.9986, loss: 0.0000,  grad a: -0.0006, grad b: 0.0003\n",
      "Itération 335:\n",
      "a: 1.9972, b: -0.9986, loss: 0.0000,  grad a: -0.0005, grad b: 0.0003\n",
      "Itération 336:\n",
      "a: 1.9972, b: -0.9986, loss: 0.0000,  grad a: -0.0005, grad b: 0.0003\n",
      "Itération 337:\n",
      "a: 1.9973, b: -0.9987, loss: 0.0000,  grad a: -0.0005, grad b: 0.0003\n",
      "Itération 338:\n",
      "a: 1.9974, b: -0.9987, loss: 0.0000,  grad a: -0.0005, grad b: 0.0003\n",
      "Itération 339:\n",
      "a: 1.9974, b: -0.9987, loss: 0.0000,  grad a: -0.0005, grad b: 0.0002\n",
      "Itération 340:\n",
      "a: 1.9975, b: -0.9987, loss: 0.0000,  grad a: -0.0005, grad b: 0.0002\n",
      "Itération 341:\n",
      "a: 1.9975, b: -0.9988, loss: 0.0000,  grad a: -0.0005, grad b: 0.0002\n",
      "Itération 342:\n",
      "a: 1.9976, b: -0.9988, loss: 0.0000,  grad a: -0.0005, grad b: 0.0002\n",
      "Itération 343:\n",
      "a: 1.9976, b: -0.9988, loss: 0.0000,  grad a: -0.0005, grad b: 0.0002\n",
      "Itération 344:\n",
      "a: 1.9976, b: -0.9988, loss: 0.0000,  grad a: -0.0005, grad b: 0.0002\n",
      "Itération 345:\n",
      "a: 1.9977, b: -0.9989, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 346:\n",
      "a: 1.9977, b: -0.9989, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 347:\n",
      "a: 1.9978, b: -0.9989, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 348:\n",
      "a: 1.9978, b: -0.9989, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 349:\n",
      "a: 1.9979, b: -0.9989, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 350:\n",
      "a: 1.9979, b: -0.9990, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 351:\n",
      "a: 1.9979, b: -0.9990, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 352:\n",
      "a: 1.9980, b: -0.9990, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 353:\n",
      "a: 1.9980, b: -0.9990, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 354:\n",
      "a: 1.9981, b: -0.9990, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 355:\n",
      "a: 1.9981, b: -0.9991, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 356:\n",
      "a: 1.9981, b: -0.9991, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 357:\n",
      "a: 1.9982, b: -0.9991, loss: 0.0000,  grad a: -0.0004, grad b: 0.0002\n",
      "Itération 358:\n",
      "a: 1.9982, b: -0.9991, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 359:\n",
      "a: 1.9982, b: -0.9991, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 360:\n",
      "a: 1.9983, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 361:\n",
      "a: 1.9983, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 362:\n",
      "a: 1.9983, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 363:\n",
      "a: 1.9984, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 364:\n",
      "a: 1.9984, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0002\n",
      "Itération 365:\n",
      "a: 1.9984, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 366:\n",
      "a: 1.9985, b: -0.9992, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 367:\n",
      "a: 1.9985, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 368:\n",
      "a: 1.9985, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 369:\n",
      "a: 1.9986, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 370:\n",
      "a: 1.9986, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 371:\n",
      "a: 1.9986, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 372:\n",
      "a: 1.9986, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 373:\n",
      "a: 1.9987, b: -0.9993, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 374:\n",
      "a: 1.9987, b: -0.9994, loss: 0.0000,  grad a: -0.0003, grad b: 0.0001\n",
      "Itération 375:\n",
      "a: 1.9987, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 376:\n",
      "a: 1.9987, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 377:\n",
      "a: 1.9988, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 378:\n",
      "a: 1.9988, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 379:\n",
      "a: 1.9988, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 380:\n",
      "a: 1.9988, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 381:\n",
      "a: 1.9989, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 382:\n",
      "a: 1.9989, b: -0.9994, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 383:\n",
      "a: 1.9989, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 384:\n",
      "a: 1.9989, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 385:\n",
      "a: 1.9989, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 386:\n",
      "a: 1.9990, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 387:\n",
      "a: 1.9990, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 388:\n",
      "a: 1.9990, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 389:\n",
      "a: 1.9990, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 390:\n",
      "a: 1.9990, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 391:\n",
      "a: 1.9991, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 392:\n",
      "a: 1.9991, b: -0.9995, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 393:\n",
      "a: 1.9991, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 394:\n",
      "a: 1.9991, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 395:\n",
      "a: 1.9991, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 396:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 397:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 398:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 399:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 400:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0002, grad b: 0.0001\n",
      "Itération 401:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 402:\n",
      "a: 1.9992, b: -0.9996, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 403:\n",
      "a: 1.9993, b: -0.9996, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 404:\n",
      "a: 1.9993, b: -0.9996, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 405:\n",
      "a: 1.9993, b: -0.9996, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 406:\n",
      "a: 1.9993, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 407:\n",
      "a: 1.9993, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 408:\n",
      "a: 1.9993, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 409:\n",
      "a: 1.9993, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 410:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 411:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 412:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 413:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 414:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 415:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 416:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 417:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 418:\n",
      "a: 1.9994, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 419:\n",
      "a: 1.9995, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 420:\n",
      "a: 1.9995, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0001\n",
      "Itération 421:\n",
      "a: 1.9995, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 422:\n",
      "a: 1.9995, b: -0.9997, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 423:\n",
      "a: 1.9995, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 424:\n",
      "a: 1.9995, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 425:\n",
      "a: 1.9995, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 426:\n",
      "a: 1.9995, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 427:\n",
      "a: 1.9995, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 428:\n",
      "a: 1.9995, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 429:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 430:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 431:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 432:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 433:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 434:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 435:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 436:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 437:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 438:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 439:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 440:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 441:\n",
      "a: 1.9996, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 442:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 443:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 444:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 445:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 446:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 447:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 448:\n",
      "a: 1.9997, b: -0.9998, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 449:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 450:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 451:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 452:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 453:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 454:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 455:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 456:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0001, grad b: 0.0000\n",
      "Itération 457:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 458:\n",
      "a: 1.9997, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 459:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 460:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 461:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 462:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 463:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 464:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 465:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 466:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 467:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 468:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 469:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 470:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 471:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 472:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 473:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 474:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 475:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 476:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 477:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 478:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 479:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 480:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 481:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 482:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 483:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 484:\n",
      "a: 1.9998, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 485:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 486:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 487:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 488:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 489:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 490:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 491:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 492:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 493:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 494:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 495:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 496:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 497:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 498:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 499:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 500:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 501:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 502:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 503:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 504:\n",
      "a: 1.9999, b: -0.9999, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 505:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 506:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 507:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 508:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 509:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 510:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 511:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 512:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 513:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 514:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 515:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 516:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 517:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 518:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 519:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 520:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 521:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 522:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 523:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 524:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 525:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 526:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 527:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 528:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 529:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 530:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 531:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 532:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 533:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 534:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 535:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 536:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 537:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 538:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 539:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 540:\n",
      "a: 1.9999, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 541:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 542:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 543:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 544:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 545:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 546:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 547:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 548:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 549:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 550:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 551:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 552:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 553:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 554:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 555:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 556:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 557:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 558:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 559:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 560:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 561:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 562:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 563:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 564:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 565:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 566:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 567:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 568:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 569:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 570:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 571:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 572:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 573:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 574:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 575:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 576:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 577:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 578:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 579:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 580:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 581:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 582:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 583:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 584:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 585:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 586:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 587:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 588:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 589:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 590:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 591:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 592:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 593:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 594:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 595:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 596:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 597:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 598:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 599:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 600:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 601:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 602:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 603:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 604:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 605:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 606:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 607:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 608:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 609:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 610:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 611:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 612:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 613:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 614:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 615:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 616:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 617:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 618:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 619:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 620:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 621:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 622:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 623:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 624:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 625:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 626:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 627:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 628:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 629:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 630:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 631:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 632:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 633:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 634:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 635:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 636:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 637:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 638:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 639:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 640:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 641:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 642:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 643:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 644:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 645:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 646:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 647:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 648:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 649:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 650:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 651:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 652:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 653:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 654:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 655:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 656:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 657:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 658:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 659:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 660:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 661:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 662:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 663:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 664:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 665:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 666:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 667:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 668:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 669:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 670:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 671:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 672:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 673:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 674:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 675:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 676:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 677:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 678:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 679:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 680:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 681:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 682:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 683:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 684:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 685:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 686:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 687:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 688:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 689:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 690:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 691:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 692:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 693:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 694:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 695:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 696:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 697:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 698:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 699:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 700:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 701:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 702:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 703:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 704:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 705:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 706:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 707:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 708:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 709:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 710:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 711:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 712:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 713:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 714:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 715:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 716:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 717:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 718:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 719:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 720:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 721:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 722:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 723:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 724:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 725:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 726:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 727:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 728:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 729:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 730:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 731:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 732:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 733:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 734:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 735:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 736:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 737:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 738:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 739:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 740:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 741:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 742:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 743:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 744:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 745:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 746:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 747:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 748:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 749:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 750:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 751:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 752:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 753:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 754:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 755:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 756:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 757:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 758:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 759:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 760:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 761:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 762:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 763:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 764:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 765:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 766:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 767:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 768:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 769:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 770:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 771:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 772:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 773:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 774:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 775:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 776:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 777:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 778:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 779:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 780:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 781:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 782:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 783:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 784:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 785:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 786:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 787:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 788:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 789:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 790:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 791:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 792:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 793:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 794:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 795:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 796:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 797:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 798:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 799:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 800:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 801:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 802:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 803:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 804:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 805:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 806:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 807:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 808:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 809:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 810:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 811:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 812:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 813:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 814:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 815:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 816:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 817:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 818:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 819:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 820:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 821:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 822:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 823:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 824:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 825:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 826:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 827:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 828:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 829:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 830:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 831:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 832:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 833:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 834:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 835:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 836:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 837:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 838:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 839:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 840:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 841:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 842:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 843:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 844:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 845:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 846:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 847:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 848:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 849:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 850:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 851:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 852:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 853:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 854:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 855:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 856:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 857:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 858:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 859:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 860:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 861:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 862:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 863:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 864:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 865:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 866:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 867:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 868:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 869:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 870:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 871:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 872:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 873:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 874:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 875:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 876:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 877:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 878:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 879:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 880:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 881:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 882:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 883:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 884:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 885:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 886:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 887:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 888:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 889:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 890:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 891:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 892:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 893:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 894:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 895:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 896:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 897:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 898:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 899:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 900:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 901:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 902:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 903:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 904:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 905:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 906:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 907:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 908:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 909:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 910:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 911:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 912:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 913:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 914:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 915:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 916:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 917:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 918:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 919:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 920:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 921:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 922:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 923:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 924:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 925:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 926:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 927:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 928:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 929:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 930:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 931:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 932:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 933:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 934:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 935:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 936:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 937:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 938:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 939:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 940:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 941:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 942:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 943:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 944:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 945:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 946:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 947:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 948:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 949:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 950:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 951:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 952:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 953:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 954:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 955:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 956:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 957:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 958:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 959:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 960:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 961:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 962:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 963:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 964:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 965:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 966:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 967:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 968:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 969:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 970:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 971:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 972:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 973:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 974:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 975:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 976:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 977:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 978:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 979:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 980:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 981:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 982:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 983:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 984:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 985:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 986:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 987:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 988:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 989:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 990:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 991:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 992:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 993:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 994:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 995:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 996:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 997:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 998:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n",
      "Itération 999:\n",
      "a: 2.0000, b: -1.0000, loss: 0.0000,  grad a: -0.0000, grad b: 0.0000\n"
     ]
    }
   ],
   "source": [
    "a_true = 2.0\n",
    "b_true = -1.0\n",
    "\n",
    "x = torch.rand((10,)) # simulation des données\n",
    "y = a_true * x + b_true\n",
    "\n",
    "a = torch.zeros(1,requires_grad=True) # les objets que l'on va faire converger vers les valeurs recherchées\n",
    "b = torch.zeros(1,requires_grad=True) # requires_grad => un champs gradient est attaché à l'objet crée\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    y_est = a*x + b # je connais x, j'estime y / paramètres estimés courants \n",
    "                    # cette ligne crée un graphe de calcul entre x et y_est mettant en jeu a et b \n",
    "\n",
    "    loss = torch.mean((y_est-y)**2) # je calcule l'erreur entre l'estimation et les valeurs observées\n",
    "    \n",
    "    loss.backward() # je différencie la fonction de perte\n",
    "                    # cela entraine la différentiation automatique de tout le graphe de calcul\n",
    "                    # le gradient est mis à jour dans toutes les variables du graphe / requires_grad = True\n",
    "    \n",
    "    print(f'Itération {i}:')\n",
    "    print(f\"a: {a.item():.4f}, b: {b.item():.4F}, loss: {loss.item():.4f},  grad a: {a.grad.item():.4f}, grad b: {b.grad.item():.4f}\")\n",
    "   \n",
    "    with torch.no_grad(): #je vais effectuer des opérations sur des objets attachés au graphe de calcul \n",
    "                          # mais je ne veux pas que ces opérations entrent dans l'optimisation des paramètres\n",
    "        \n",
    "        a -=  0.1*a.grad # descente de gradient de pas 0.1\n",
    "        b -=  0.1*b.grad\n",
    "        \n",
    "        a.grad.zero_() # je remets à 0 tous les champs gradient des objets\n",
    "        b.grad.zero_()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ee4c4",
   "metadata": {},
   "source": [
    "# Définition d'un réseau de neurones \n",
    "\n",
    "## Complètement à la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e529bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonModeleQuiTorche(torch.nn.Module):\n",
    "    def __init__(self,delta_chan=4,verbose=False):\n",
    "        if verbose:\n",
    "            self.print = print\n",
    "        else:\n",
    "            self.print = lambda x:None\n",
    "        self.print('Initialisation classe mère \\n')\n",
    "        torch.nn.Module.__init__(self) \n",
    "        \n",
    "        self.print('\\n Initialisation classe courante \\n')\n",
    "        self.delta_chan=delta_chan\n",
    "        self.learnable_param = torch.nn.Parameter(torch.rand([1,delta_chan,1]))\n",
    "        self.not_learnable_param = torch.rand((1,delta_chan,1))\n",
    "\n",
    "    def __setattr__(self,name,value):\n",
    "        super().__setattr__(name,value)\n",
    "        self.print(f'Enregistrement de: {name} à la valeur {value}')\n",
    "        \n",
    "    def forward(self,x): \n",
    "        #x is [B,input_chan,T]\n",
    "        # output is [B,self.output_chan,T]\n",
    "        x_reduced = torch.mean(x , axis = 1 , keepdim=True)\n",
    "        x_duplicated = torch.tile(x_reduced , dims = (1, self.delta_chan, 1))\n",
    "\n",
    "        y0 = self.learnable_param *x_duplicated \n",
    "        y1 = y0+ self.not_learnable_param\n",
    "\n",
    "        y2 = torch.abs(y1)\n",
    "        \n",
    "        y3 = torch.concat([x, y2], axis=1)\n",
    "        return y3\n",
    "    \n",
    "    def __call__(self,x):\n",
    "    # Défini dans la classe mère\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28e0bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enregistrement de: print à la valeur <built-in function print>\n",
      "Initialisation classe mère \n",
      "\n",
      "\n",
      " Initialisation classe courante \n",
      "\n",
      "Enregistrement de: delta_chan à la valeur 4\n",
      "Enregistrement de: learnable_param à la valeur Parameter containing:\n",
      "tensor([[[0.4109],\n",
      "         [0.7455],\n",
      "         [0.6436],\n",
      "         [0.6213]]], requires_grad=True)\n",
      "Enregistrement de: not_learnable_param à la valeur tensor([[[0.5034],\n",
      "         [0.2785],\n",
      "         [0.6202],\n",
      "         [0.6244]]])\n"
     ]
    }
   ],
   "source": [
    "mon_modele=MonModeleQuiTorche(delta_chan=4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3040ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape torch.Size([5, 1, 100]), output shape torch.Size([5, 5, 100]), second output shape torch.Size([5, 9, 100])\n"
     ]
    }
   ],
   "source": [
    "x= torch.rand(5,1,100)\n",
    "y = mon_modele(x)\n",
    "z = mon_modele(y)\n",
    "print(f'Input shape {x.shape}, output shape {y.shape}, second output shape {z.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f219586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramètres du modèle : \n",
      " {'learnable_param': Parameter containing:\n",
      "tensor([[[0.4109],\n",
      "         [0.7455],\n",
      "         [0.6436],\n",
      "         [0.6213]]], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "print(f'Paramètres du modèle : \\n {mon_modele._parameters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd46f0b",
   "metadata": {},
   "source": [
    "## En enchaînant des couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55293b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_modele_sequentiel = torch.nn.Sequential( \n",
    "  MonModeleQuiTorche(4),\n",
    "  MonModeleQuiTorche(5),\n",
    "  MonModeleQuiTorche(6)  )\n",
    "\n",
    "mon_modele_sequentiel(torch.rand(5,1,100)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b573aa",
   "metadata": {},
   "source": [
    "### Quand il y en a beaucoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44022367",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = torch.nn.Sequential(*[MonModeleQuiTorche(4+i) for i in range(10)])\n",
    "print(mlp((torch.rand(5,1,100))).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d8d93",
   "metadata": {},
   "source": [
    "## Couches linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4abbe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(in_features=40,\n",
    "                         out_features=100\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad515649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is torch.Size([10, 40])\n",
      "Output shape is torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand([ 10, 40])\n",
    "print(f'Input shape is {x.shape}')\n",
    "y = linear(x)\n",
    "print(f'Output shape is {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71bc605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de paramètres à apprendre :  4100\n"
     ]
    }
   ],
   "source": [
    "print(f'Nombre de paramètres à apprendre :  {sum(p.numel() for p in linear.parameters() if p.requires_grad)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259a108",
   "metadata": {},
   "source": [
    "### Couches linéaires sur un signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57dbfef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is torch.Size([10, 4, 10])\n",
      "x flatten shape is : torch.Size([10, 40])\n",
      "Output shape is torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand([10, 4, 10]) #[B, C, T]\n",
    "print(f'Input shape is {x.shape}')\n",
    "x_flat = torch.flatten(x, start_dim = 1 , end_dim=2)\n",
    "print(f'x flatten shape is : {x_flat.shape}')\n",
    "y = linear(x_flat)\n",
    "print(f'Output shape is {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f9c92",
   "metadata": {},
   "source": [
    "## Couches de convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ee4507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv1d(in_channels=4,  # entrée [B,1,T]\n",
    "                       out_channels=10, # sortie [B,10,T']\n",
    "                       kernel_size=11, # préférer les nombres impairs \n",
    "                       stride=1,       # T' = T//2\n",
    "                       padding='same', # idem (kernel_size-1)//2 \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30b5d9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is torch.Size([10, 4, 100])\n",
      "Output shape is torch.Size([10, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand([10, 4, 100]) #[B, C, T]\n",
    "print(f'Input shape is {x.shape}')\n",
    "\n",
    "y = conv(x)\n",
    "print(f'Output shape is {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nombre de paramètres à apprendre :  {sum(p.numel() for p in conv.parameters() if p.requires_grad)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b270a",
   "metadata": {},
   "source": [
    "## Convolutions séparables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0841790",
   "metadata": {},
   "outputs": [],
   "source": [
    "depthwise = torch.nn.Conv1d(in_channels=4,  # entrée [B,1,T]\n",
    "                           out_channels=4,  # sortie [B,4,T]\n",
    "                           groups= 4,       # correspond à in_channels\n",
    "                           kernel_size=11,  # préférer les nombres impairs \n",
    "                           stride=1,  \n",
    "                           padding='same'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointwise = torch.nn.Conv1d(in_channels=4,  # entrée [B,1,T]\n",
    "                           out_channels=10,  # sortie [B,4,T]\n",
    "                           kernel_size=1,   # préférer les nombres impairs \n",
    "                           stride=1, \n",
    "                           padding='same'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35336750",
   "metadata": {},
   "outputs": [],
   "source": [
    "separable_convolution = torch.nn.Sequential(depthwise,\n",
    "                                            pointwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([10, 4, 100]) #[B, C, T]\n",
    "print(f'Input shape is {x.shape}')\n",
    "\n",
    "y = separable_convolution(x)\n",
    "print(f'Output shape is {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e050754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nombre de paramètres à apprendre :  {sum(p.numel() for p in separable_convolution.parameters() if p.requires_grad)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e59b2",
   "metadata": {},
   "source": [
    "## Couches récurrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent = torch.nn.RNN(input_size=6, # x is [B, T , input_size]\n",
    "                        hidden_size =15, # h is [B,T, hidden_size]\n",
    "                        num_layers =1, # par défaut\n",
    "                        batch_first=True,  # pour que la première dimension soit bien le batch\n",
    "                        bidirectional= False, # par défaut\n",
    "                         bias= False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49291ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.rand([20, 100,6])\n",
    "h , h_layers_end = recurrent(x)\n",
    "print(h.shape)\n",
    "print(h_layers_end.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nombre de paramètres à apprendre :  {sum(p.numel() for p in recurrent.parameters() if p.requires_grad)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47920dd1",
   "metadata": {},
   "source": [
    "###  Réseau récurrent avec deux couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent = torch.nn.RNN(input_size=6, # x is [B, T , input_size]\n",
    "                        hidden_size =15, # h is [B,T, hidden_size]\n",
    "                        num_layers =4, # h de la couche 0 devient le x de la couche 1 etc.\n",
    "                        batch_first=True,  # pour que la première dimension soit bien le batch\n",
    "                        bidirectional= False, # valeur par défaut\n",
    "                        bias= False\n",
    "\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3981ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.rand([20, 100,6])\n",
    "h , h_layers_end = recurrent(x)\n",
    "print(h.shape)\n",
    "print(h_layers_end.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a09488",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nombre de paramètres à apprendre :  {sum(p.numel() for p in recurrent.parameters() if p.requires_grad)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee0b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9a122d0",
   "metadata": {},
   "source": [
    "###  Réseau récurrent bidirectionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db232a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent = torch.nn.RNN(input_size=6, # x is [B, T , input_size]\n",
    "                        hidden_size =15, # h is [B,T, hidden_size]\n",
    "                        num_layers =7, # h de la couche 0 devient le x de la couche 1 etc.\n",
    "                        batch_first=True,  # pour que la première dimension soit bien le batch\n",
    "                        bidirectional= True, # cf Algorithme forward backward\n",
    "                         bias = False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d79f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.rand([20, 100,6])\n",
    "h , h_layers_end = recurrent(x)\n",
    "print(h.shape)\n",
    "print(h_layers_end.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nombre de paramètres à apprendre :  {sum(p.numel() for p in recurrent.parameters() if p.requires_grad)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6834d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(6+15)*15*2 + 6*(15*2 + 15 )*(15)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0faad",
   "metadata": {},
   "source": [
    "# Pipeline d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_data):\n",
    "        ...\n",
    "    def __len__(self): #returns int\n",
    "        ...\n",
    "    def __getitem__(self,i): #returns (data_i,label_i)\n",
    "        ...\n",
    "\n",
    "dataset = MyDataset(...)\n",
    "\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=10, \n",
    "                        shuffle=True\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86990f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class metric_logger:\n",
    "    \n",
    "    def __init__(self,...):\n",
    "        ...\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        ... \n",
    "        \n",
    "    def update_metrics(self, batch_x,batch_y_true,batch_y_pred):\n",
    "        ...\n",
    "    \n",
    "        return {'metric0':...,\n",
    "               'metric1':...\n",
    "               }\n",
    "    \n",
    "    def log(self):\n",
    "        ...\n",
    "\n",
    "device = 'cpu' # set so 'cuda:xx' if you have a GPU, xx is GPU index\n",
    "model = ... \n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "metric_logger_train = metric_logger(...)\n",
    "metric_logger_valid = metric_logger(...)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    metric_logger_train.reset()\n",
    "    \n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        \n",
    "        batch_x.to(device)\n",
    "        batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_y_predicted = model(batch_x)\n",
    "        \n",
    "        l = loss(batch_y_predicted, batch_y)\n",
    "        \n",
    "        metric_logger_train.log(batch_x,batch_y,batch_y_predicted)\n",
    "        \n",
    "        l.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    for batch_x,batch_y in dataloader_valid:\n",
    "        \n",
    "        batch_x.to(device)\n",
    "        batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_y_predicted = model(batch_x)  \n",
    "            \n",
    "        metric_logger_valid.log(batch_x,batch_y,batch_y_predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E4C",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
